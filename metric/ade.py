import torch
from typing import Any, Callable, Optional
from torchmetrics import Metric


class ADE(Metric):
    full_state_update: Optional[bool] = False
    higher_is_better: Optional[bool] = False

    def __init__(
            self,
            # compute_on_step: bool = True,
            dist_sync_on_step: bool = False,
            process_group: Optional[Any] = None,
            dist_sync_fn: Callable = None,
    ) -> None:
        super(ADE, self).__init__(
            # compute_on_step=compute_on_step,
            dist_sync_on_step=dist_sync_on_step,
            process_group=process_group,
            dist_sync_fn=dist_sync_fn,
        )
        self.pred, self.target = 0, 0
        self.add_state("sum", default=torch.tensor(0.0), dist_reduce_fx="sum")
        self.add_state("count", default=torch.tensor(0), dist_reduce_fx="sum")

    def update(self, pred, target):
        self.pred = pred
        self.target = target
        with torch.no_grad():
            avg_ade = torch.norm(pred - target, p=2, dim=-1).mean(dim=-1)
            self.sum += avg_ade.sum()
            self.count += avg_ade.shape[0] 

    def compute(self) -> torch.Tensor:
        return self.sum / self.count
